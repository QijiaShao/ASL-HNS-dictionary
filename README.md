## Teaching American Sign Language in Mixed Reality

ASL-HNS-dictionary used in [Teaching American Sign Language in Mixed Reality]()


The dictionary was developed by collaborators at Dartmouth College and Gallaudet University.
Each word included in the dictionary contains a link to a video of the sign in the online resource ASL Signbank [1], information about the type of sign (e.g. one or two handed), and a translation of the sign into Hamburg Notation System or HamNoSys, an phonetic transcription system for codifying signed words into symbols which is designed for use with many signed languages, not only ASL. Unless otherwise noted, the handshape described for dynamic signs is the inital handshape, and any changes to the handshape that occur during the execution of the sign are described in the “movement” column. For detailed information about the conventions of HNS, please see Hanke et al. [2]
These translations were created for use with an animated web avatar such as those referenced here (http://vh.cmp.uea.ac.uk/index.php/Main_Page), and some values were chosen for optimal results with the avatar rather than phonetic correctness. 
We just started the process of building this ASL-HNS-dictionary. It currently contains 56 words and we welcome anyone interested in to contribute.

## References


[1] Julie A. Hochgesang, Onno Crasborn, and Diane Lillo-Martin. (2017-2020) ASL Signbank. New Haven, CT: Haskins Lab, Yale University. https://aslsignbank.haskins.yale.edu/  

[2] Hanke, T. (2004), “HamNoSys - representing sign language data in language resources and language processing contexts.” In: Streiter, Oliver, Vettori, Chiara (eds): LREC 2004, Workshop proceedings : Representation and processing of sign languages. Paris : ELRA, 2004, - pp. 1-6.)
